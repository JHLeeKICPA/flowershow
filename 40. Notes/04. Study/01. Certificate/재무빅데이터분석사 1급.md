## 0. 파이썬, Fraudit 기본

### 1. 함수

#### filter(func, list)
- **boolean 함수**와 **시퀀스 데이터**(리스트, 튜플 등)를 인자로 받아서 시퀀스 데이터의 각 요소에 대해 boolean 함수를 적용하고 그 결과가 True인 요소만으로 구성된 새로운 객체 반환 → 입력 개수보다 결과 개수가 작거나 같음
```python
list_raw = [1,2,3,4,5,6]
list_filtered = filter(lambda x: x % 2 ==0, list_raw)
print(list(list_filtered))
>>> [2,4,6]
```

#### map(func, list)
- **변환함수**와 **시퀀스 데이터**를 인자로 받아서 시퀀스 데이터의 각 요소에 변환 함수를 적용하고 그 결과로 구성된 새로운 객체를 반환 → 입력 개수와 결과 개수는 항상 동일
```python
list_raw = [1,2,3,4,5,6]
list_mapped = map(lambda x: x**2, list_raw)
print(list(list_mapped))
>>> [1,4,9,16,25]
```
#### enumerate(list)
- 괄호 안의 시퀀스 자료의 **인덱스와 원소를 함께 추출해서 튜플로 나타내는 함수**
```python
a = ['a', 'b', 'c']
for i in enumerate(a):
	print(i)
>>> (0, 'a')
>>> (1, 'b')
>>> (2, 'c')

for i, j in enumerate(a):
	print(i, j)
>>> 0 a
>>> 1 b
>>> 2 c
```

#### zip(list1, list2)
- 2개 이상의 시퀀스형 자료의 원소를 묶어서 튜플로 만들어 주는 함수
```python
a = ['a','b','c']
b = [1,2,3]
print(list(zip(a,b)))
>>> [('a',1), ('b',2), ('c',3)]
```

### 2. 리스트 컴프리헨션

#### 문법
- `{python title:기본구조} [식 for 원소 in 시퀀스 자료]`
- `{python | title:if문}[i for i in range(5) if i % 2 == 0] `
- `{python | title:if문}[i if i % 2 == 0 else None for i in range(5)]`
- `{python | title:중첩for문}[i*j for i in range(2,4) for j in range(7,10)]`

#### 활용
- apply 함수 대신 이용
```python
df['차변잔액'] = [if[0] - i[1] if i[0] >= i[1] else 0 
			for i in zip(df['차변합계'],df['대변합계'])]
```

### 3. Fraudit

#### Table
- Fraudit의 테이블은 가로 세로 2차원 테이블 형식의 변수
	- `Table[i]` : 인덱스 i 행의 값들로 구성된 **리스트**
	- `Table[i][j]` : 인덱스 i 행의 값들 중 j번째 값 
	- `Table['a']` : 컬럼 **객체**
	- `Table['a'][j]` :  컬럼의 j행 값

#### TableArray
- TableArray는 여러 개의 sub table로 구성됨
	- `TableArray[i]` : i번째 **서브테이블**
- TableArray에 산식을 포함하는 칼럼을 추가하는 코드
```python
# 각 sub 테이블의 'A'열의 레코드 값 중 최대값을 나타내는 'A_최댓값' 열 생성
for i in range(len(table)):
	for j in range(len(table[i])):
		table[i]['A_최대값'][j] = max(res1[i]['A'])
```

#### Table과 DataFrame 변환
- Table → DataFrame : `{python} df = table.toDF()
- DataFrame → Table : `{python} table = Table(data = df)

## 1. Numpy

### 1. Numpy 기초
#### 1. 데이터타입
- 데이터타입 종류 : integer(i), unicode string(U), string(S), datetime(M)등
- 데이터타입 변환 : astype()
	- `{python} array = array.astype("M")

#### 2. Array 생성
- array() 함수
	- `{python} array = np.array(list1) #리스트를 numpy 배열로 변환 `
	- `{python} array = np.array(list1, list2, list3) #리스트들을 numpy 2차원 배열로 변환 `
- arrange() 함수
	- `{python} array = np.arrange(x) #0부터 x미만 정수 배열 생성`
	- `{python} array = np.arrange(x,y) #x이상 y 미만의 정수 배열 생성`
	- `{python} array = np.arrange(x,y,z) #x이상 y 미만의 정수 배열을 z간격으로 생성`
- ones() 함수
	- `{python} array = np.ones(x) #x개의 1로 구성된 배열 생성
	- `{python} array = np.ones((x,y,z)) #x개조합, y행, z열 배열 생성
- zeros() 함수
	- `{python} array = np.zeros(x) #x개의 0로 구성된 배열 생성`
	- `{python} array = np.zeros((x,y,z)) #x개조합, y행, z열 배열 생성
- eyes() 함수
	- `{python} array = eyes(x) #x차 단위행렬 배열 생성`
- random() 함수
	- `{python} np.random.seed(n) #seed를 고정
	- `{python} array = np.random.rand(n) #0부터 1사이의 균등분포에서 난수 배열 생성`
	- `{python} array = np.random.randn(n) #평균 0, 표준편차 1의 표준정규분포를 가지는 난수 배열 생성`
	- `{python} array = np.random.randint(n,m,x)#특정 범위(n이상 m 미만) 사이의 임의의 정수 x개 배열 생성`

#### 3. Array 출력
- 2차원 배열 출력
	- `{python} print(array[n:m, x:y]) #행 인덱스: n:m / 열 인덱스: x:y
- ndim
	- `{python} array.ndim #array의 dimension(차원) 수`
- shape
	- `{python} array.shape #array의 shape(행, 열)`

#### 4. 항목 추가, 삭제
- 항목 추가 
	- `{python} array = np.append(기존 array, "추가항목", axis = 0 or 1) # axis = 0: 행 추가 / axis=1: 열 추가
- 항목 삭제
	- `{python}array = np.delete(기존array, [idx1, idx2], axis = 0 or 1) # 기존 array에서 index 값 삭제, axis = 0: 행 삭제 / axis=1: 열 삭제`

### 2. Numpy 조작

#### 1. 정렬
- np.sort()
	- `{python} array = np.sort(array) #기존 array를 변경하지 않음`
	- `{python} array = np.sort(array)[: : -1] #오름차순`
- array.sort()
	- `{python} array.sort() #기존 array를 변경`
- 2차원 array 정렬
	- axis = 1 : 각 행별로 1열, 2열, 3열 순으로 정렬 **(default)**
	- axis = 0 : 각 열별로 1행, 2행, 3행 순으로 정렬
#### 2. 모양 바꾸기
- reshape()
	- `{python} array2 = np.reshape(array,(n,m)) #n행 m열`
	- `{python} array2 = np.reshape(array,(-1)) #1차원으로 변환

#### 3. 조건을 만족하는 인덱스 반환, 값 반환
- np.where()
	- `{python} np.where(조건식, x, y) #조건식이 true이면 x, false이면 y 반환 / 생략시 인덱스 반환`
		- `index도 배열로 반환`
	- `{python} array[np.where(조건식)] #조건을 만족하는 값 반환`

### 3. 기타

#### 1. 반전 변환
- `{python} array2 = np.filpud(array) #상하 반전`
- `{python} array2 = np.filplr(array) #좌우 반전`
- `{python} array2 = np.filp(array) #상하,좌우 반전`

#### 2. Numpy 연산
- 행렬 곱
	- `{python} array_곱 = np.dot(array1, array2)
- 역행렬
	- `{python} array_역행렬 = np.linalg.inv(array)`
- 브로드캐스팅
	- 차원의 짝이 맞거나 최소한 하나의 array 차원이 1일때 배열의 형태를 연산할 수 있 자동으로 맞춰주는 기능

#### 3. 히스토그램
- `{python} numpy.histogram(array, bins = 10, range = None, normed = None, weights = None, density = None)
	- `(output) array[구간별 발생빈도], dtype, array[구간 파라미터]`

## 2. Pandas

### 1. Series

#### 1. Series 기초
- 시리즈 생성 : `{python} series = Series([1, 2, 3], index =['a', 'b', 'c'] )`
- 인덱스 확인 : `{python} series.index`
- 값 확인 : `{python}series.values`
- 원소 개수 확인 : `{python} series.size

#### 2. Series 연산, 조건식
- 시리즈 간 연산
	- 동일한 인덱스끼리 연산, 한 쪽에만 존재하거나 None 데이터와의 연산은 NaN
- 시리즈 조건식
	- `{python} series[series > 1000]
	- `{python} series.isnull()

### 2. Dataframe

#### 1. Dataframe 기초
- 생성
	- `{python title:Dataframe()} df = Dataframe({'칼럼명1' : [원소1, 원소2, …, 원소 n], '칼럼명2' : [원소1, 원소2, …, 원소 n], '칼럼명3' : [원소1, 원소2, …, 원소 n]})
	- `{python title:read_csv} df = pd.read_csv("filename.csv", encoding = "utf-8")`
	- `{python title:from_reocrds} df = pd.DataFrame.from_records(data)
- 조회
	- 특정 인덱스의 값 가져오기 : `{python} df.iloc[n] #n행 가져오기`
	- 특정 값 가져오기
		- `{python} df.iloc[n]['a'] #n행의 'a'열 데이터 가져오기`
		- `{python} df['a'][n] #n행의 'a'열 데이터 가져오기`
		- `{python} df.iloc[0:n] #0부터 n-1까지 행 가져오기`
		- `{python} df.iloc[0:n, 0:m] #0부터 n-1까지 행 및 0부터 m-1열 가져오기`
- 삭제
	- 칼럼 삭제 : `{python} df = df.drop(columns = '칼럼명')`
	- 행 삭제 : `{python} df = df.drop(index = n, axis = 0)

#### 2. 필터링, 정렬, 칼럼 편집
- 필터링(조건을 충족하는 행만 가져오기)
	- `{python title:단일조건} df[df['칼럼명'] == '값'] `
	- `{python title:복합조건(and)} df[(df['칼럼명1'] == '값') & (df['칼럼명2'] == '값')`
	- `{python title:복합조건(or)} df[(df['칼럼명1'] == '값') | (df['칼럼명2'] == '값')`
- 정렬
	- `{python} df.sort_values(['칼럼명'])`
	- `{python} df.sort_values(by = ['칼럼명'], axis = 0, ascending = True)` 
		- `{python} axis = 0`: 행 정렬(default) / `{python} axis = 1`: 열 정렬
		- `{python} ascending = True` : 오름차순 / `{python} ascending = False` : 내림차순
- 칼럼 편집
	- 칼럼 헤더 반환 : `{python} header_list = df.columns`
	- 칼럼 순서 변경 : `{python} df = df[['c', 'b', 'a']] #열 순서 변경`
	- 칼럼 안의 NaN 변환 : `{python} df['칼럼명'] = df['칼럼명'].fillna("변환할 값")`

#### 3. 데이터프레임 결합
- pd.concat()
	- `{python} df_concat = pd.concat([df1, df2])
		- `{python} axis = 0` : 위아래로 결합(default) / `{python} axis = 1` : 좌우로 결합
		- `{python} ignore_index = True` : 인덱스를 순서대로 재정렬(default는 False)
		- `{python} join = 'inner'`: inner join / `{python} join = outer` : outer join
- pd.merge()
	- `{python} df_merge = pd.merge(df1, df2)` or `{python} df_merge = df1.merge(df2)`
		- `{python} how='inner'` : inner join **(default)** / `{python} how='outer'` : outer join / `{python} how='left'` : left outer join / `{python} how='right'` : right outer join
		- `{python} on = "칼럼명"` : 칼럼명을 기준으로 join(default : 칼럼명이 같은 열 기준)
			- 왼쪽칼럼과 오른쪽 칼럼 이름이 다른 경우 `left_on`, `right_on`사용
- reduce 함수
```python
from functools import reduce
df_reduce = reduce(lambda x,y: pd.merge(x,y, on = '칼럼명', how = 'inner'), [df1, df2])
```

#### 4. 피벗테이블
- 피벗테이블 생성
	- `{python} pivot_table = pd.pivot_table(df, index = ['칼럼명1', '칼럼명2'], values = '칼럼명', columns = '칼럼명', aggfunc = '산식', fill_value = '변환값', margins = True)`
		- index : 인덱스 열
		- values : 집계할 데이터 열
		- columns : 집계 데이터 하위 칼럼
		- aggfunc : 집계할 산식
		- margins : 총계 산식을 넣고 싶은 경우 True로 추가
- 필터링
	- `{python} pivot_table = pivot_table.query("인덱스 헤더 == ['인덱스1', 인덱스2']")
- 헤더 순서 변경
	- `{python} df = df.reindex(['칼럼명1', '칼럼명2'], level = 1, axis = 1)`
		- level : 칼럼의 레벨

### 3. Pandas 함수

#### groupby



#### filter

#### apply

groupby로 **새로운 데이터프레임**을 만들고 싶을 때

#### transform

**기존 데이터프레임**에 groupby로 생성된 데이터 열을 추가하고 싶을 때


## 정규표현식

### 1. 주요 메타 문자

- `.` : 임의의 모든 character 1개
- `^` : 줄의 시작
- `$` : 줄의 끝
- `|` : 또는
-  대괄호(`[ ]`)
	- 대괄호 안에서 문자열 : 문자 중 어느 한 개
	- 대괄호 안에서 `^` : 해당 문자를 제외
	- 대괄호 안에서 `-` : 문자 범위 지정
- 소괄호(`( )`) : 문자열을 묶음으로 봄
- 숫자, 문장
	- `\d` : 숫자를 의미 (=`[0-9])
	- `\D` : 숫자를 제외한 것을 의미 (= `[^0-9]`)
	- `\s` : 공백문자를 의미
	- `\S` : 공백문자를 제외한 것을 의미
	- `\b` : 단어의 시작과 끝의 빈 공백을 의미
	- `\B` : 단어의 시작과 끝을 제외한 빈 공백을 의미
	- `\w` : 숫자와 알파벳 문자를 의미 (=`[a-zA-Z0-9]`)
	- `\W` : 숫자와 알파벳 문자를 제외한 것을 의미
- 반복
	- `*` : 0회 이상 반복
	- `*?` : 0회 이상 반복(최소 매칭 non-greedy)
	- `+` : 1회 이상 반복
	- `+?` : 1회 이상 반복(최소 매칭 non-greedy)
	- `?` : 0회 or 1회
	- `{m}` : m회 반복
	- `{m, n}` : m회에서 n회까지 반복
- 전방탐색
	- 긍정형 전방탐색 : `(?=전방탐색문자)` → 검색에는 포함되지만 검색 결과에는 제외
	- 부정형 전방탐색 : `(?!전방탐색문자)` → 전방탐색문자가 없는 것만 검색

### 2. 정규식 함수

- match(패턴, 문자열)
	- 문자열의 시작부터 패턴이 매치하는지 검사하고 존재하면 MatchObject, 없으면 None 반환
- search(패턴, 문자열)
	- 문자열 전체에서 패턴이 1개 존재하는지 검사하고 존재하면 MatchObject, 없으면 None 반환
- findall(패턴, 문자열)
	- 문자열에서 패턴을 만족하는 문자열의 리스트를 반환
- split(패턴, 문자열)
	- 문자열에서 구분자로 분리하여 리스트를 반환
- sub(패턴, 대체, 문자열)
	- 문자열에서 패턴과 일치하는 부분을 대체

## 네트워크 분석

- 무방향 그래프(쌍방향)
	- `{python} G= nx.Graph
- 노드 생성
	- `{python} G.add_nodes_from([1,2,3])`
- 엣지 생성
	- `{python} G.add_edges(1,2)`
## 문제유형별 코드

### 몬테카를로

#### 신제품 총이익이 일정 금액 이상일 확률

```python
# 라이브러리 임포트
import mcerp
from mcerp import *

# 1. 시뮬레이션 횟수 설정, 시드 고정
mcerp.npts = 10000
np.random.seed(0)

# 2. 파라미터 설정
min_quantity, mode_quantity, max_quantity = 8000.0, 12000.0, 18000.0
avg_price, std_price = 20.0, 1.0
avg_cost, std_cost = 13.0, 0.7
etc_cost = 3.0

# 3. 입력변수 분포
quantity = PERT(min_quantity, mode_quantity, max_quantity)
price = N(avg_price, std_price)
cost = N(avg_cost, std_cost)

# 4. 결과 산식
revenue = quantity * price
total_cost = quantity * (cost + etc_cost)
profit = revenue - total_cost

# 5. 확률 구하기
print(profit > 35000)
```

#### 주당순이익이 일정 금액 이상일 확률

```python
# 라이브러리 임포트
import mcerp
from mcerp import *

# 1. 시뮬레이션 횟수 설정,시드 고정
mcerp.npts = 10000
np.random.seed(0)

# 2. 파라미터 설정
revenue_mu = [i for i in 추정손익계산서[0][1:]]
revenue_sigma = [i*0.1 for i in 추정손익계산서[0][1:]]
cogs_rate = np.array(과거매출원가율['매출원가율'])

# 3. 매출원가 최적 분포 찾기
dist = distfit()
dist.fit_transform(cogs_rate)
print(dist.summary.T) #결과: score가 가장 작은 분포 선택(lognorm)

# 4. 입력변수 분포
revenue = [N(i[0],i[1]) for i in zip(revenue_mu, revenue_sigma)]
cog = uv(ss.lognorm(0.025737381821119332, loc = 0.219736, scale = 0.398737)) # arg, loc, scale 입력
sga = Tri(0.06, 0.07, 0.08)

# 5. 결과 산식
eps = 0
for i in revenue:
    eps = eps + (i - i * cog - i * sga - 180000000) * (1-0.24) / 100000

# 6. 확률 구하기
print(eps >= 57000)
```

### 옵션 평가

#### 풋옵션, 콜옵션 평가
```python
np.set_printoptions(precision = 4, suppress = True)

# 1. 기초변수 설정
S = 100 ; e = 120 ; rf = 0.06 ; t = 3 ; n = 300 ; v = 0.2 ; dt = t / n
r = np.exp(-rf*dt)

# 2. u와 d 계산
u = np.exp(v * np.sqrt(dt))
d = np.exp(-v * np.sqrt(dt))

#3. p 계산
p = (np.exp(rf*dt)-d) / (u-d)

#4. 주가트리 생성
s_tree = np.zeros([n+1,n+1])
for i in range(n+1):
    for j in range(i+1):
        s_tree[j,i] = s * (u **(i-j)) * (d**j)

#5. 옵션트리 생성
o_tree = np.zeros([n+1, n+1])
o_tree[:,n] = np.maximum((s_tree[:,n]-e),0)

#6. 옵션가치 산출(콜옵션 : max(주가 - 행사가격, 0) / 풋옵션: max(행사가격 - 주가, 0)
for node in range(n-1,-1,-1):
    for time in range(n-1,-1,-1):
        if time >= node:
            o_tree[node, time] = np.maximum(s_tree[node,time] - e,
            (o_tree[node, time+1]*p + o_tree[node+1, time+1] * (1-p)) * r)

print(o_tree)
```

#### 기하 브라운 운동 콜옵션 평가
```python
import numpy as np
import math as m
np.set_printoptions(precision=4, suppress=True)

# 1. 기초변수 설정
S = 100 ; e = 120 ; rf = 0.06 ; t = 3 ; n = 300 ; v = 0.2 ; dt = t / n
r = np.exp(-rf*dt)

# 2. 시뮬레이션 횟수 정하기
N_SIMS = 10000

# 3. 기하 브라운 모형(GBM)에 따라 변화하는 주가를 나타내는 사용자 함수
def simulate_gbm(s_0, mu, sigma, n_sims, T, N):
	dt = T/N
	np.random.seed(seed =1)
	dZ = np.random.normal(scale = np.sqrt(dt), size = (n_sims, N))
	Z = np.cumsum(dZ, axis = 1)
	time_step = np.linspace(dt, T, N)
	time_steps = np.broadcast_to(time_step, (n_sims, N))
	S_t = s_0 *np.exp((mu -0.5 *sigma **2)*time_steps + sigma*Z)
	S_t = np.insert(S_t, 0, 최초주가, axis = 1)
	return S_t
# 4. 상기 사용자 함수에 기초변수를 넣어 array를 생성
gbm_sims = simulate_gbm(s_0 = 최초주가, mu = 무위험이자율, sigma = 변동성, n_sims = N_SIMS, T = 만기, N = 노드)

# 5. 행사가격 구하기 : 아시안이므로 만기일까지의 평균주가를 구한다.
행사가격 = np.mean(gbm_sims, axis=1) # 1차원 어레이로 결과가 나온다.
행사가격 = np.array([행사가격]) # 행렬변환 전단계 처리
행사가격 = 행사가격.T # 브로드캐스트를 위한 행렬변환
# payoff matrix 생성하기
payoff_matrix = np.round(np.maximum(gbm_sims - 행사가격 , np.zeros_like(gbm_sims)),2)
# 만기 시점의 칼럼의 payoff_matrix 값만 있는 매트릭스를 작성
value_matrix = np.zeros_like(payoff_matrix)
value_matrix[:, -1] = payoff_matrix[:, -1]
# 최종옵션가치 도출
전체할인계수 = np.exp(-무위험이자율*dt*노드) # 년 환산 할인해야 하므로 dt*노드를
변경
option_premium = np.mean(value_matrix[:, -1] * 전체할인계수)
print(option_premium)
	
	
	
```

### 정규표현식

#### random.text에서 데이터 추출해서 연봉합계 최고지역 입력
```python
df = pd.read_csv('random_data.csv', header = None)

# 1. 지역 리스트 작성
sido_list = [
 '서울특별시', '부산광역시', '대구광역시', '인천광역시', '광주광역시', 
        '대전광역시', '울산광역시', '세종특별자치시', '경기도', '강원도', 
        '충청북도', '충청남도', '전라북도', '전라남도', '경상북도', '경상남도', 
        '제주특별자치도'
    ]

# 2. 랜덤 데이터를 한 열에 순서대로 합산
df_flat = df.stack().reset_index(drop=True) #한 열에 합산

# 3. 지역, 연봉 데이터 추출(정규표현식)
sido = []
salary = []

for i in df_flat:
    if i in sido_list:
        sido.append(i)
    match = re.search(r'(,\d{3}원$)|(^\\.*)|(,\d{3}$)', i)
    if match:
        salary.append(int(match.group(0).replace(',','').replace('원','').replace('₩','')))

# 4. 데이터프레임 생성
df_result = pd.DataFrame({'sido' : sido, 'salary': salary})

# 5. 연봉합계 최고지역 찾기
a = df_result.groupby('sido')['salary'].agg(['sum'])
print(a)
```

#### 적요에서 데이터 추출해서 연봉합계 최저지역 입력
```python
df = pd.read_csv('적요.csv')

juso_pattern = r'(경기도|강원도|충청북도|충청남도|전라북도|전라남도|경상북도|경상남도|제주특별자치도|\w*특별시|\w*광역시|\w*자치시)'
salary_pattern = r'(연봉\s\d+원|연봉\s₩\d+)'

juso_list = []
salary_list = []

df['juso'] = df['적요'].apply(lambda x: re.search(juso_pattern, x).group(1))
df['salary'] = df['적요'].apply(lambda x: re.search(salary_pattern, x).group(1).replace("연봉 ","").replace("원","").replace("₩",""))

df['salary'] = df['salary'].astype('int')

df2 = df.groupby('juso')['salary'].sum().reset_index()

df3 = df2.sort_values('salary')
```

### 분개장 분석

#### 차변합계와 대변합계 불일치 전표세트 개수

```python
# dataframe 임포트
df = pd.read_csv("대량분개장.csv")

# 1.'차변 - 대변' 열 추가 / '전표세트' 열 추가
df['차변-대변'] = df['차변금액'] - df['대변금액']
df['전표세트'] = df.groupby(['전표일자','전표번호']).ngroup() 

# 2. 전표세트 groupby 후 reset_index
df2 = df.groupby('전표세트').sum(['차변-대변']).reset_index() 

# 3. 차변, 대변 합계 불일치 행 추출
answer = len(df2[df2['차변-대변'] != 0.0])
print(answer)
```

#### 현금매출 전표세트 개수
```python
# dataframe 임포트
df = pd.read_csv("대량분개장.csv")

# 1. '전표세트' 열 추가
df['전표세트'] = df.groupby(['전표일자','전표번호']).ngroup()

# 2. 대상 계정과목 리스트 작성
a = [i for i in range(10080,10086)]
b = [i for i in range(40001,40014)]

# 3. 현금매출 전표세트 추출
df2 = df.groupby('전표세트').filter(lambda x: (
    ((x['계정코드'].isin(a)) & (x['차변금액'] > 0)).any() and
    ((x['계정코드'].isin(b)) & (x['대변금액'] > 0)).any()
))
print(len(df2))
```

#### 분개패턴 분석
```python
df = pd.read_csv("대량분개장.csv")

#계정코드_1 열 삽입
df['계정코드_1'] = [i[2] if i[0] > 0 and i[1] == 0
                else(-i[2] if i[0] < 0 and i [1] == 0
                else(-i[2] if i[0] == 0 and i[1] > 0
                else(i[2] if i[0] == 0 and i[1] < 0
                else(i[2] if i[0] == 0 and i[1] == 0
                else 0))))
                for i in zip(df['차변금액'],df['대변금액'],df['계정코드'])
                ]
# 1. '전표세트' 열 추가
df['전표세트'] = df.groupby(['전표일자','전표번호']).ngroup()

# 2. 중복을 제외한 계정코드_1의 합계,표준편차 열 삽입
df['계정코드_합계'] = df.groupby('전표세트')['계정코드_1'].transform(lambda x:x.unique().sum())
df['계정코드_표준편차'] = df.groupby('전표세트')['계정코드_1'].transform(lambda x:x.unique().std())

# 3. 계정코드_1의 합계, 표준편차로 groupby 후 인덱스 열 삽입
df['계정코드_1_인덱스'] = df.groupby(['계정코드_합계','계정코드_표준편차']).ngroup()

# 4. 계정코드_1 인덱스로 groupby 후 고유한 전표세트 개수 추출
df2 = df.groupby('계정코드_1_인덱스')['전표세트'].nunique()
print(len(df2[df2==1]))
```

#### RSF 테스트
```python
df = pd.read_csv("대량분개장.csv")

#1. 외상매출금 차변 행만 추출
df2 = df[(df['계정과목'] == '외상매출금_1') & (df['차변금액'] > 0)].copy()

#2. RSF열 생성
df2['RSF'] = df2.groupby('거래처코드')['차변금액'].transform(
    lambda x: x.max() / x.nlargest(2).iloc[1] if len(x) > 1 and x.nlargest(2).iloc[1] != 0 else 0)

# 3. RSF가 50 초과하는 거래처 추출
print(df2[df2['RSF'] >50]['거래처코드'].nunique())
```

#### 매출취소 전표세트 개수
```python
df = pd.read_csv("대량분개장_1.csv")

# 1. '전표세트' 열 추가
df['전표세트'] = df.groupby(['전표일자', '전표번호']).ngroup()

# 2. 대상 계정과목 리스트 생성
a = [i for i in range(40000, 40014)]

# 3. 매출취소 전표 추출
df2 = df.groupby('전표세트').filter(lambda x: (
((x['계정코드'].isin(a)) & (x['차변금액']>0)).any() or 
((x['계정코드'].isin(a)) & (x['대변금액']<0)).any())
)
print(df2['전표세트'].nunique())

```

#### 전표세트의 개수가 2개인 거래처코드 개수
```python
df = pd.read_csv("대량분개장_1.csv")

# 1. '전표세트' 열 추가
df['전표세트'] = df.groupby(['전표일자', '전표번호']).ngroup()

# 2. 대상 계정과목 리스트 작성
a = [i for i in range(10080,10086)]
b = [i for i in range(40001,40014)]

# 3. 대상 계정코드 거래처가 존재하는 행 추출
df2 = df[(df['거래처코드'] != 0 | df['거래처코드'].notna()) & df['계정코드'].isin(a)]

# 4. 거래처코드별로 groupby해서 고유한 전표세트 개수 추출
df3 = df2.groupby('거래처코드')['전표세트'].nunique()
print(len(df3[df3 == 2]))

```

#### 야간시간 입력 / 주말 입력 전표
```python
import datetime as dt
from datetime import **
df = pd.read_csv('분개장.csv')

# 1. 입력일자가 존재하는 전표만 추출
df2 = df[df['입력일자'].notna()]

# 2. 입력시간 열 추가
df2['입력시간'] = df2['입력일자'].apply(lambda x: x.split(' ')[1])
df2['입력시간_1'] = df2['입력일자'].apply(lambda x: x.split(' ')[2].split(':')[0]).astype(int)

# 3. 요일 열 추가
df2['요일'] = df2['입력일자'].dt.weekday()

#3. 입력시간이 야간인 행 추출
df3 = df2[
((df2['입력시간'] == '오후') & ((df2['입력시간_1'] >= 7)&(df2['입력시간_1'] < 12))) | 
((df2['입력시간'] == '오전') & ((df2['입력시간_1'] < 6)|(df2['입력시간_1'] == 12)))
]
print(len(df3))
```

#### 전표세트를 가장 많이 입력한 입력사원이 입력한 전표 개수
```python
df = pd.read_csv('분개장.csv')

# 1. '전표세트' 열 추가
df['전표세트'] = df.groupby(['전표일자', '전표번호']).ngroup()

# 1. 입력사원으로 groupby하여 전표번호 count
df2 = df.groupby('입력사원')['전표세트'].nunique()

#2. reset_index 이후 정렬
df2.reset_index().sort_values('전표세트')
```

#### 라인번호가 1부터 시작하지 않거나 1씩 증가하지 않는 전표세트
```python
df = pd.read_csv('분개장_07회_1급_1.csv')
# 정렬
df = df.sort_values(by = ['전표일자', '전표번호', '전표라인번호'])

# 전표일자와 전표번호 칼럼을 기준으로 groupby 한다.
gb_1 = df.groupby(['전표일자', '전표번호'])

# "전표라인번호"를 비교하기 위해 한 칸 위(이전 행)의 값을 shift하여 새 칼럼 추가
df['전표라인번호_prev'] = gb_1['전표라인번호'].shift(1).fillna(0).astype(int)

# 전표라인번호 차이 계산
df['라인번호_차이'] = df['전표라인번호'] - df['전표라인번호_prev']

# 전표라인번호가 1보다 큰 구간(즉, 누락 / 점프가 있는 구간) 식별
df_gap = df[df['라인번호_차이'] != 1]
print(df_gap)
```

#### 외상매출금 잔액이 있는 거래처 개수
1. Data - Group - By Value에서 거래처 칼럼으로 그루핑
2. Analyze - Digital Analysis - Add Vlookup으로 전기이월 열 추가
3. Analyze - Digital Analysis - Add Cumsum Column으로 차변, 대변 누적 칼럼 삽입
4. 잔액 칼럼 삽입
5. 잔액 칼럼의 마지막 레코드가 0을 초과하는 서브 테이블 구하기
```python
for i in range(len(외상매출금_거래처)) :
	for j in range(len(외상매출금_거래처[i])) :
		if 외상매출금_거래처[i][len(외상매출금_거래처[i])-1]['잔액'] > 0 :
			외상매출금_거래처[i][j]['판단'] = 1
		else :
			외상매출금_거래처[i][j]['판단'] = 0
```

#### Value Search
1. Table Property 메뉴에서 총수익, 매출원가 컬럼 타입을 Decimal Number로 변경
2. Data - Summarize - By value에서 총수익, 매출원가 sum을 컬럼 설정
3. 매출총이익률 컬럼 생성

### 최적화


